{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884ad119",
   "metadata": {},
   "source": [
    "# Environment Tester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f3bcbe",
   "metadata": {},
   "source": [
    "- The following notebook is meant to be a quick summary/verification of your computers environment.\n",
    "- Please run all of the cells to get all of the information displayed. \n",
    "    - Either Press `Shift + Enter` to run each cell \n",
    "    - OR Click on `Kernel`> `Restart & Run All`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeb364",
   "metadata": {},
   "source": [
    "## Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cac8d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'Troubleshooting/Troubleshooting Report.ipynb.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/IPython/core/magics/execution.py:696\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    695\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 696\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/IPython/utils/path.py:91\u001b[0m, in \u001b[0;36mget_py_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[0;31mOSError\u001b[0m: File `'Troubleshooting/Troubleshooting Report.ipynb.py'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ## Exporting Troubleshooting report\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTroubleshooting/Troubleshooting Report.ipynb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2305\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2305\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/IPython/core/magics/execution.py:707\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[1;32m    706\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
      "\u001b[0;31mException\u001b[0m: File `'Troubleshooting/Troubleshooting Report.ipynb.py'` not found."
     ]
    }
   ],
   "source": [
    "# ## Exporting Troubleshooting report\n",
    "%run \"Troubleshooting/Troubleshooting Report.ipynb\"\n",
    "\n",
    "# with open(\"FINAL_REPORT.txt\") as f:\n",
    "# \tfinal_report = f.read()\n",
    "# # print(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c407030",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recording time notebook was run\n",
    "import datetime as dt\n",
    "from tzlocal import get_localzone, get_localzone_name\n",
    "now = dt.datetime.now(get_localzone())\n",
    "now_nice = now.strftime(\"%m/%d/%Y @ %I:%M:%S %p \") + f\"(tz={get_localzone_name().split('/')[-1]})\"\n",
    "print(f'[i] Environment Tester Notebook started at: {now_nice}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fedf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET CURRENT ENVIRONMENT INFO\n",
    "%conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK PYTHON VERSION (should be 3.9.15)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder path to python\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Home folder\n",
    "import os\n",
    "print(os.environ['HOME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024806d",
   "metadata": {},
   "source": [
    "## Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe05fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5.2\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.24.4\n",
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6.2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.12.1\n",
    "import seaborn as sns\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa602f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.3\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203919a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.9.3\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "sp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0.2\n",
    "import pymysql\n",
    "pymysql.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.13.2\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "statsmodels.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8.5\n",
    "import pmdarima as pmd\n",
    "pmd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.41.0\n",
    "import shap\n",
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ba727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.10.0\n",
    "import imblearn\n",
    "imblearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae01bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6.7\n",
    "import dython \n",
    "dython.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003549e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As long as m1 mac installed the m1 env, this should work\n",
    "# should be 2.9.1 (or 2.11)\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.3\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c174c",
   "metadata": {},
   "source": [
    "## Jupyter Notebook Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b23bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter_contrib_nbextensions==0.5.1\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable jupyter_nbextensions_configurator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e89862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!jupyter nbextension enable toc2/main\n",
    "!jupyter nbextension enable collapsible_headings/main\n",
    "!jupyter nbextension enable ruler/main\n",
    "!jupyter nbextension enable livemdpreview/livemdpreview \n",
    "!jupyter nbextension enable spellchecker/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHeck if nbextensions installed\n",
    "# !jupyter nbextension list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67398f8b",
   "metadata": {},
   "source": [
    ">- **Note: if you see any warning messages about `x: problems found`**, but your notebook continued to run the following cells, your environment is working fine!\n",
    "    - nbextensions will often display this message, but in reality everything is fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807d6f2",
   "metadata": {},
   "source": [
    "## Shell/Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc62def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# shell = !echo $SHELL\n",
    "shell = os.environ['SHELL']\n",
    "shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67795f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32030b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python path\n",
    "# os.environ['PYTHONPATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5defd",
   "metadata": {},
   "source": [
    "### Display the Profile For Your Terminal/GitBash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01955b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c56c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ## Checking .bash_profile or .zshrc\n",
    "# if 'zsh' in shell[0]:\n",
    "#     print(f'[i] Using .zshrc')\n",
    "#     fname = r\"~/.zshrc\"\n",
    "# else:\n",
    "#     print(f'[i] Using .bash_profile')\n",
    "fname = r\"~/.bash_profile\"\n",
    "    \n",
    "profile = !cat {fname}\n",
    "print('\\n'.join(profile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea8363",
   "metadata": {},
   "source": [
    "# Package Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26f7e0",
   "metadata": {},
   "source": [
    "## Pandas Profiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRsXeEswMPJqEh9xpXed0eJYaQf_aKkNCypU4TKvGrS_hucLW2IWUxrVBjlKQJR4Z_EQFE-YR4UUuTz/pub?output=csv\",\n",
    "                index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "# report = ProfileReport(df)\n",
    "# report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12cf9f6",
   "metadata": {},
   "source": [
    "## MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0aab1e",
   "metadata": {},
   "source": [
    "### Scikit-learn v.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector,make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping column that are not helpful\n",
    "bad_cols = ['Name','Ticket']\n",
    "df.drop(columns=bad_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e52019",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specifying root names of types of features to loop through and filter out from df\n",
    "target_col = 'Survived'\n",
    "drop_cols = ['Cabin']\n",
    "\n",
    "y = df[target_col].copy()\n",
    "X = df.drop(columns=[target_col,*drop_cols]).copy()\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=321)\n",
    "y_train.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature selectors\n",
    "cat_sel = make_column_selector(dtype_include='object')\n",
    "num_sel = make_column_selector(dtype_include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create pipelines and column transformer\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scale',StandardScaler())])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value='MISSING')),\n",
    "    ('encoder',OneHotEncoder(sparse=False,handle_unknown='ignore',\n",
    "                             drop='first'))])\n",
    "                           \n",
    "                           \n",
    "                           \n",
    "## COMBINE BOTH PIPELINES INTO ONE WITH COLUMN TRANSFORMER\n",
    "preprocessor=ColumnTransformer(transformers=[\n",
    "    ('num',num_transformer,num_sel),\n",
    "    ('cat',cat_transformer,cat_sel)], verbose_feature_names_out=False)\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit preprocessing pipeline on training data and pull out the feature names and X_cols\n",
    "preprocessor.fit(X_train)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "## Transform X_traian,X_test and remake dfs\n",
    "X_train_df = pd.DataFrame(preprocessor.transform(X_train),\n",
    "                          index=X_train.index, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(preprocessor.transform(X_test),\n",
    "                          index=X_test.index, columns=feature_names)\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(model,X,y_true, classes=None, normalize='true',\n",
    "                            cmap=\"Blues\",  label=\"Test Data\", figsize=(5,3)): \n",
    "\n",
    "    ## Get Predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    ## Classification Report / Scores \n",
    "    dashes = '---'*20\n",
    "    print(dashes)\n",
    "    print(f\"[i] CLASSIFICATION REPORT FOR: {label}\")\n",
    "    print(dashes)\n",
    "    \n",
    "    print(metrics.classification_report(y_true,y_pred,\n",
    "                                        target_names=classes))\n",
    "    # print(dashes)\n",
    "    \n",
    "\n",
    "    ## Plot a confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    metrics.ConfusionMatrixDisplay.from_predictions(y_true,y_pred,\n",
    "                                                         normalize=normalize,\n",
    "                                                        cmap=cmap,ax=ax)\n",
    "#     cm = metrics.confusion_matrix(y_true,y_pred,normalize=normalize,)\n",
    "#     # plt.figure(figsize=figsize)\n",
    "#     ax = sns.heatmap(cm, annot=True,square=True,cmap=cmap)\n",
    "\n",
    "    if classes != None:\n",
    "        ## Label classes\n",
    "        ax.set_xticklabels(classes)\n",
    "        ax.set_yticklabels(classes,rotation=0)\n",
    "\n",
    "    ## Add axis labels & title\n",
    "    ax.set_ylabel('True Classes')\n",
    "    ax.set_xlabel('Predicted Classes')\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_df,y_train)\n",
    "evaluate_classification(rf,X_test_df,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7db28",
   "metadata": {},
   "source": [
    "## MODEL EXPLANATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f30dff",
   "metadata": {},
   "source": [
    "### Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap \n",
    "print(shap.__version__)\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize an explainer with the model\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "\n",
    "## Calculaate shap values for test data\n",
    "shap_values = explainer.shap_values(X_test_df,y_test)\n",
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1],X_test_df,max_display=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b10a9",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbe6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "lime_explainer =LimeTabularExplainer(\n",
    "    training_data=np.array(X_test_df),\n",
    "    feature_names=X_test_df.columns,\n",
    "    class_names=['Died', 'Survived'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "row = np.random.choice(range(len(X_test_df)))\n",
    "target_lookup = {0:'Died',1:'Survived'}\n",
    "\n",
    "print(f\"- Row #: {row}\")\n",
    "print(f\"Class = {target_lookup[y_test.iloc[row]]}\")\n",
    "\n",
    "exp = lime_explainer.explain_instance(X_test_df.iloc[row], rf.predict_proba)\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18accc0",
   "metadata": {},
   "source": [
    "## ADVANCED MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dd82b",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10da2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train_df, y_train)\n",
    "evaluate_classification(rf,X_test_df,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838205f",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e836ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "clf = LGBMClassifier()\n",
    "clf.fit(X_train_df, y_train)\n",
    "evaluate_classification(rf,X_test_df,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0736b45",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQVbSOFab3WcS31FfOdDE7pYxSuo_O7epFxACZElgwUt1gId7qPtn7krQbp39NyAwoAtR7aTdYYtDOw/pub?output=csv',\n",
    "                parse_dates=['CrimeDateTime'],index_col=0)\n",
    "display(df_crime.head())\n",
    "df_crime.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07564cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick a time series from above to work with\n",
    "ts = df_crime['LARCENY']\n",
    "ts.plot(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01331e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ts.resample('M').sum().loc[:\"2021\"]\n",
    "ts.plot(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35023ced",
   "metadata": {},
   "source": [
    "### Statsmodels.tsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as tsa\n",
    "## import seasonal_decompose\n",
    "decomp_mul = tsa.seasonal_decompose(ts,model='mul')#,model='mul')\n",
    "\n",
    "mpl.rcParams['figure.figsize']=(12,6)\n",
    "decomp_mul.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split Index\n",
    "train_size = 0.8\n",
    "split_idx = round(len(ts)* train_size)\n",
    "split_idx\n",
    "\n",
    "## Split\n",
    "train = ts.iloc[:split_idx]\n",
    "test = ts.iloc[split_idx:]\n",
    "\n",
    "## Visualize split\n",
    "fig,ax= plt.subplots()\n",
    "kws = dict(ax=ax,marker='o')\n",
    "train.plot(**kws)\n",
    "test.plot(**kws)\n",
    "ax.legend(bbox_to_anchor=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as tsa\n",
    "d = 1\n",
    "p = 1\n",
    "q =1\n",
    "model = tsa.SARIMAX(train,order=(p,d,q),).fit()\n",
    "display(model.summary())\n",
    "model.plot_diagnostics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66399c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "forecast = model.forecast(steps=len(test))\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba703f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting a forecast\n",
    "forecast = model.get_forecast(len(test))\n",
    "\n",
    "\n",
    "def forecast_to_df(forecast, name='forecast'):\n",
    "    test_pred = forecast.conf_int()\n",
    "    test_pred[name] = forecast.predicted_mean\n",
    "    test_pred.columns = ['lower','upper','prediction']\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "pred_df = forecast_to_df(forecast)#,district)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416feba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "train.plot(ax=ax,label='train')\n",
    "test.plot(ax=ax,label='test')\n",
    "\n",
    "pred_df['prediction'].plot(ax=ax,label='forecast',ls='--')\n",
    "\n",
    "ax.fill_between(x=pred_df.index,y1=pred_df['lower'],y2=pred_df['upper'])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb95d68",
   "metadata": {},
   "source": [
    "## pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima\n",
    "# help(pmdarima.auto_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = pmdarima.auto_arima(train,start_p=0,start_q=0)\n",
    "display(auto_model.summary())\n",
    "# help(auto_model\n",
    "auto_model.plot_diagnostics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda607de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean,pred_conf_int = auto_model.predict(return_conf_int=True)\n",
    "pred_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ba81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'pred':pred_mean, \n",
    "                        'conf_int_lower':pred_conf_int[:,0],\n",
    "                        'conf_int_upper':pred_conf_int[:,1]},\n",
    "                        index= pd.date_range(test.index[0],\n",
    "                                                  periods=10,freq='M'))\n",
    "# auto_model.conf_int()\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebbfe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tsa.SARIMAX(ts,order=auto_model.order,\n",
    "                     seasonal_order=auto_model.seasonal_order).fit()\n",
    "display(best_model.summary())\n",
    "best_model.plot_diagnostics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_pred(train,test,pred_df):\n",
    "    fig,ax = plt.subplots()\n",
    "    kws = dict(marker='o')\n",
    "    \n",
    "    ax.plot(train,label='Train',**kws)\n",
    "    ax.plot(test,label='Test',**kws)\n",
    "    ax.plot(pred_df['prediction'],label='prediction',ls='--',**kws)\n",
    "\n",
    "    ax.fill_between(x=pred_df.index,y1=pred_df['lower'],y2=pred_df['upper'])\n",
    "    ax.legend(bbox_to_anchor=[1,1])\n",
    "    fig.tight_layout()\n",
    "    return fig,ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.get_forecast(steps=12)#start=test.index[0],end=test.index[-1])\n",
    "pred_df = forecast_to_df(pred)\n",
    "display(plot_train_test_pred(train,test,pred_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b0962",
   "metadata": {},
   "source": [
    "## Pandas DataReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "try:\n",
    "    example = pdr.DataReader('GOOGL','yahoo','2012','2020')\n",
    "    display(example.head(10))\n",
    "except: \n",
    "    print('[!] There is a back-end issue with Pandas DataReader and Yahoo finance (as of 12/22/22).')\n",
    "    print(\"\\t- So don't worry... your env is fine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f2253",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2ac01",
   "metadata": {},
   "source": [
    "## Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.line(data_frame=df_crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7303d",
   "metadata": {},
   "source": [
    "## Sklearn `plot_tree`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56befdbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "tree = rf.estimators_[0]\n",
    "plot_tree(tree);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d3b9a",
   "metadata": {},
   "source": [
    "## Yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815162b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yellowbrick.datasets import load_credit\n",
    "# from yellowbrick.features import Rank2D\n",
    "\n",
    "# # Load the credit dataset\n",
    "# X, y = load_credit()\n",
    "\n",
    "# # Instantiate the visualizer with the Pearson ranking algorithm\n",
    "# visualizer = Rank2D(algorithm='pearson')\n",
    "\n",
    "# visualizer.fit(X, y)           # Fit the data to the visualizer\n",
    "# visualizer.transform(X)        # Transform the data\n",
    "# visualizer.show()              # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593bc419",
   "metadata": {},
   "source": [
    "# Final Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4c97a",
   "metadata": {},
   "source": [
    "- You should see the success message printed below the last code cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[i] SUCCESS. YOUR ENVIRONMENT IS FULLY FUNCTIONAL AND READY TO USE!\")\n",
    "end = dt.datetime.now(get_localzone())\n",
    "end_nice = end.strftime(\"%m/%d/%Y @ %I:%M:%S %p \") + f\"(tz={get_localzone_name().split('/')[-1]})\"\n",
    "print(f'    - Time Completed: {end_nice}')\n",
    "\n",
    "duration = end-now\n",
    "print(f'    - Total Time = {(end-now) } (\"HH:MM:SS.ms\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4de360",
   "metadata": {},
   "source": [
    "- If the message did not print, your notebook ran into an error somewhere above. \n",
    "\t- Scroll up to find the last cell that ran.\n",
    "\t- If an error message is displayed, follow the steps below to save a copy of the notebook to send to an instructor for help.\n",
    "\n",
    "### Files to Share for Troubleshooting\n",
    "\n",
    "- There are 2 files that you should share with your instructor/TA\n",
    "\t1. A copy of your Environment Tester notebook that error'd.\n",
    "\t2. A copy of \"FINAL_REPORT.txt\" file that is in the Troubleshooting folder of the repo.\n",
    "\t\n",
    "1. To share your notebook with an instructor/TA for help:\n",
    "\t- Click File > Save & Checkpoint.\n",
    "\t- Click File > Download As > Notebook (.ipynb)\n",
    "\t- You web browser should save a copy of the notebook to your normal \"Downloads\" folder.\n",
    "    \n",
    "<img src=\"images/download_as.png\" width=600px>\n",
    "\n",
    "2. To share a copy of your FINAL_REPORT.txt:\n",
    "\t- In the first Files tab that opened when you started jupyter notebook you should see a folder called \"Troubleshooting\"\n",
    "\t- Click on the troublshooting folder. \n",
    "\t- Inside the folder you should have a file called \"FINAL_REPORT.txt\".\n",
    "\t- Check the checkbox next to the file and the click on the \"Download\" button that appears at the top of the list of files.\n",
    "\t- Your web browser will also save this file to your Downloads folder.\n",
    "    \n",
    "<img src=\"images/download_report.png\" width=600px>\n",
    "\n",
    "- **Post your question on the [ds-python-installation](https://discord.com/channels/738494436467539968/999108307627294770) Discord channel and tag your instructor in your question (e.g. @dojo_instructor_name).**\n",
    "\t- Attach the 2 files listed above.\n",
    "\t- Add any additional details or info you think may be helpful for us to know.\n",
    "\t\t- For example:\n",
    "\t\t\t- \"my computer is really old and I think that may be part of the problem.\"\n",
    "\t\t\t- \"I share this computer with someone else who also uses python\"\n",
    "\t\n",
    "- An instructor or TA will get back to you within 1 business day with the next steps for you to try.\n",
    "\t- You will most likely need to set up a Zoom call and share your screen for us to help.\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5091413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
